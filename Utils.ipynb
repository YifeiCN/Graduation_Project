{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#jupyter 中开启该选项，否则不执行\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集随机提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick_hazy_and_gt_img()函数输出到目标地址后的文件命名规则为：雾图为原来无雾图片的名字， 无雾图片为雾图名 ＋ '_gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_hazy_and_gt_img(src_hazy_dir_path, src_gt_dir_path, dst_hazy_dir_path, dst_gt_dir_path, number, suffix, random_tag=1):\n",
    "\n",
    "    \n",
    "    gt_img_list = os.listdir(src_gt_dir_path)\n",
    "    \n",
    "    # shuffle the list of the dir\n",
    "    if random_tag == 1:\n",
    "    \n",
    "        random.shuffle(gt_img_list)\n",
    "    \n",
    "    # get number imgs\n",
    "    gt_img_list = gt_img_list[0:number]\n",
    "    \n",
    "    num_gt_copy_before = len(os.listdir(dst_gt_dir_path))\n",
    "    \n",
    "    num_hazy_copy_before = len(os.listdir(dst_hazy_dir_path))    \n",
    "    \n",
    "    \n",
    "    for gt_img in gt_img_list:\n",
    "        (gt_img_name, gt_img_form) = gt_img.split('.',-1)\n",
    "        \n",
    "        hazy_img = gt_img_name + suffix + '.' + gt_img_form\n",
    "\n",
    "        src_hazy_img_path = os.path.join(src_hazy_dir_path, hazy_img)\n",
    "        \n",
    "        src_gt_img_path = os.path.join(src_gt_dir_path, gt_img)\n",
    "\n",
    "        dst_hazy_img = gt_img\n",
    "        \n",
    "        dst_gt_img = gt_img_name + '_gt.' + gt_img_form\n",
    "        \n",
    "        dst_hazy_img_path = os.path.join(dst_hazy_dir_path, dst_hazy_img)\n",
    "        \n",
    "        dst_gt_img_path = os.path.join(dst_gt_dir_path, dst_gt_img)\n",
    "\n",
    "        # copy the src dataset to evaluate folder\n",
    "        # shutil.copyfile(src, dst)\n",
    "        shutil.copyfile(src_hazy_img_path, dst_hazy_img_path)\n",
    "        \n",
    "        shutil.copyfile(src_gt_img_path, dst_gt_img_path)\n",
    "\n",
    "    num_gt_copy_now = len(os.listdir(dst_gt_dir_path))\n",
    "    \n",
    "    num_hazy_copy_now = len(os.listdir(dst_hazy_dir_path))\n",
    "    \n",
    "    num_gt_copy = num_gt_copy_now - num_gt_copy_before\n",
    "    \n",
    "    num_hazy_copy_now = num_hazy_copy_now - num_hazy_copy_before\n",
    "    \n",
    "    print(\"Successfully copy the source dataset to evaluate folder!\")\n",
    "    \n",
    "    print(\"%d expected, %d groundtruth image done, %d hazy image done\" %(number, num_gt_copy, num_hazy_copy_now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_img(src_hazy_dir_path, src_gt_dir_path, dst_hazy_dir_path, dst_gt_dir_path, number,random_tag=1):\n",
    "    \n",
    "    \n",
    "    hazy_img_list = os.listdir(src_hazy_dir_path)\n",
    "   \n",
    "    # shuffle the list of the dir\n",
    "    if random_tag == 1:\n",
    "        \n",
    "        random.shuffle(hazy_img_list)\n",
    "        \n",
    "    # get number imgs\n",
    "    hazy_img_list = hazy_img_list[0:number]\n",
    "    \n",
    "    num_gt_copy_before = len(os.listdir(dst_gt_dir_path))\n",
    "    \n",
    "    num_hazy_copy_before = len(os.listdir(dst_hazy_dir_path))    \n",
    "    \n",
    "    \n",
    "    for hazy_img in hazy_img_list:\n",
    "\n",
    "        gt_img = hazy_img[0:4] + '.png'\n",
    "        \n",
    "        src_hazy_img_path = os.path.join(src_hazy_dir_path, hazy_img)\n",
    "        \n",
    "        src_gt_img_path = os.path.join(src_gt_dir_path, gt_img)\n",
    "\n",
    "        dst_hazy_img = gt_img\n",
    "        \n",
    "        dst_gt_img = hazy_img[0:4] + '_gt' + '.png'\n",
    "        \n",
    "        dst_hazy_img_path = os.path.join(dst_hazy_dir_path, dst_hazy_img)\n",
    "        \n",
    "        dst_gt_img_path = os.path.join(dst_gt_dir_path, dst_gt_img)\n",
    "\n",
    "        # copy the src dataset to evaluate folder\n",
    "        # shutil.copyfile(src, dst)\n",
    "        shutil.copyfile(src_hazy_img_path, dst_hazy_img_path)\n",
    "        \n",
    "        shutil.copyfile(src_gt_img_path, dst_gt_img_path)\n",
    "\n",
    "    \n",
    "    num_gt_copy_now = len(os.listdir(dst_gt_dir_path))\n",
    "    \n",
    "    num_hazy_copy_now = len(os.listdir(dst_hazy_dir_path))\n",
    "    \n",
    "    num_gt_copy = num_gt_copy_now - num_gt_copy_before\n",
    "    \n",
    "    num_hazy_copy_now = num_hazy_copy_now - num_hazy_copy_before\n",
    "    \n",
    "    print(\"Successfully copy the source dataset to evaluate folder!\")\n",
    "    \n",
    "    print(\"%d expected, %d groundtruth image done, %d hazy image done\" %(number, num_gt_copy, num_hazy_copy_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机从NYU2 数据集中抽取 number个 无雾图片及其对应的雾图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    src_hazy_dir_path = r'.\\data\\RESIDE\\SOTS\\SOTS\\outdoor\\hazy'\n",
    "    src_gt_dir_path = r'.\\data\\RESIDE\\SOTS\\SOTS\\outdoor\\gt'\n",
    "    dst_hazy_dir_path = './Graduation_project_defog/evaluate/hazy'\n",
    "    dst_gt_dir_path = './Graduation_project_defog/evaluate/groundtruth'\n",
    "    number = 1\n",
    "    suffix = '_7_2'\n",
    "    pick_hazy_and_gt_img(src_hazy_dir_path, src_gt_dir_path, dst_hazy_dir_path, dst_gt_dir_path, number, suffix=0, random_tag=1)\n",
    "    # pick_img(src_hazy_dir_path, src_gt_dir_path, dst_hazy_dir_path, dst_gt_dir_path, number,random_tag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pair(hazy_dir, gt_dir):\n",
    "    hazy_img_list = os.listdir(hazy_dir)\n",
    "    gt_img_list = os.listdir(gt_dir)\n",
    "    for hazy_img in hazy_img_list:\n",
    "        gt_img = hazy_img[0:4] + '_gt.png'\n",
    "        if gt_img not in gt_img_list:\n",
    "            print('error:%s' %hazy_img)\n",
    "    \n",
    "    print('No problems!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    hazy_dir = r'.\\evaluate\\hazy'\n",
    "    gt_dir = r'.\\evaluate\\groundtruth'\n",
    "    test_pair(hazy_dir, gt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the size of image\n",
    "# after this operation, w, h meet the condition of w%16==0. h%16==0\n",
    "def preprocess_img(img_dir_path):\n",
    "    img_list = os.listdir(img_dir_path)\n",
    "    num_img = len(img_list)\n",
    "    cutting_count = 0\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(img_dir_path,img)\n",
    "        src = cv2.imread(img_path)    #src.shape == [h,w,c]\n",
    "        (h,w) = src.shape[0:2]\n",
    "        if w%PATCH_SIZE != 0 or h%PATCH_SIZE != 0:\n",
    "            if w%PATCH_SIZE != 0:\n",
    "                w -= (w%PATCH_SIZE)\n",
    "            if h%PATCH_SIZE != 0:\n",
    "                h -= (h%PATCH_SIZE)\n",
    "            src = src[0:h, 0:w]  # 裁剪坐标为[y0:y1, x0:x1]\n",
    "            cv2.imwrite(img_path,src)\n",
    "            cutting_count += 1\n",
    "    print(\"Preprocessing Done! Total %d images, where %d cut\" %(num_img, cutting_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    PATCH_SIZE = 16\n",
    "    needprocess = ['hazy']\n",
    "    for name in needprocess:\n",
    "        dir_path = r'.\\evaluate\\\\' + name\n",
    "        preprocess_img(dir_path)\n",
    "        print(\"process done:%s\" %name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_create(root_path, folder_list):\n",
    "    \n",
    "    if not os.path.exists(root_path):\n",
    "        \n",
    "        os.mkdir(root_path)\n",
    "        \n",
    "        print(\"New create root folder...\")\n",
    "    \n",
    "    for folder_name in folder_list:\n",
    "        \n",
    "        folder_path = os.path.join(root_path,folder_name)\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            \n",
    "            os.mkdir(folder_path)\n",
    "            \n",
    "            print('New create folder: %s' %folder_name)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('Already existing folder: %s' %folder_name)\n",
    "            \n",
    "    print('Folder dir creating done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New create folder: hazy\n",
      "New create folder: groundtruth\n",
      "New create folder: proposed\n",
      "New create folder: result\n",
      "New create folder: ATM\n",
      "New create folder: BCCR\n",
      "New create folder: CAP\n",
      "New create folder: DCP\n",
      "New create folder: DehazeNet\n",
      "New create folder: FVR\n",
      "New create folder: MSCNN\n",
      "New create folder: NLD\n",
      "Folder dir creating done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    root_path = r'.\\evaluate'\n",
    "    \n",
    "    #evaluate_dataset_name = 'NYU2_200_random'\n",
    "    folder_list = ['hazy', 'groundtruth', 'proposed','result', \n",
    "                   'ATM','BCCR', 'CAP', 'DCP', 'DehazeNet', 'FVR', 'MSCNN','NLD']\n",
    "    \n",
    "    #dir_create(root_path, evaluate_dataset_name, folder_list)\n",
    "    dir_create(root_path, folder_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSD 图像加雾\n",
    "\n",
    "根据MSD深度信息合成对应雾图。\n",
    "\n",
    "根据alpha beta 值生成雾图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haze_generator(msd_dir_path, output_dir_path, generator_num_per_img=5):\n",
    "\n",
    "    if not os.path.exists(output_dir_path):\n",
    "        \n",
    "        os.mkdir(output_dir_path)\n",
    "        \n",
    "        print(\"New create output dir folder:%s\" % output_dir_path)\n",
    " \n",
    "    img_name_alphabeta = {}\n",
    "    \n",
    "    folders_tofind = msd_dir_path + '/*'\n",
    "    \n",
    "    folders = glob.glob(folders_tofind)\n",
    "    \n",
    "    for folder in folders:\n",
    "        \n",
    "        limg = cv2.imread(folder+'/view1.png', 1)/255.0\n",
    "        \n",
    "        ldis = cv2.imread(folder+'/disp1.png', 0)/3\n",
    "        \n",
    "        rimg = cv2.imread(folder+'/view5.png', 1)/255.0\n",
    "        \n",
    "        rdis = cv2.imread(folder+'/disp5.png', 0)/3\n",
    "        \n",
    "        for i in range(1, ldis.shape[0]):\n",
    "            \n",
    "            for j in range(ldis.shape[1]):\n",
    "                \n",
    "                if (ldis[i,j] == 0):\n",
    "                    \n",
    "                    ldis[i, j] = ldis[i-1, j]\n",
    "                    \n",
    "                if (rdis[i,j] == 0):\n",
    "                    \n",
    "                    rdis[i, j] = rdis[i-1, j]\n",
    "                    \n",
    "        for i in range(ldis.shape[0]):\n",
    "            \n",
    "            for j in range(1, ldis.shape[1]):\n",
    "                \n",
    "                if (ldis[i,j] == 0):\n",
    "                    \n",
    "                    ldis[i, j] = ldis[i, j-1]\n",
    "                    \n",
    "                if (rdis[i,j] == 0):\n",
    "                    \n",
    "                    rdis[i, j] = rdis[i, j-1]\n",
    "                    \n",
    "        ldis = np.clip(ldis, 1, ldis.shape[1])\n",
    "        \n",
    "        rdis = np.clip(rdis, 1, rdis.shape[1])\n",
    "        \n",
    "        ldepth = 3740*0.016/ldis\n",
    "        \n",
    "        rdepth = 3740*0.016/rdis\n",
    "    \n",
    "        for c in range(generator_num_per_img):\n",
    "            \n",
    "            alpha = random.uniform(0.75, 1.0)\n",
    "            \n",
    "            beta = random.uniform(0, 1.5)\n",
    "            \n",
    "            lt = np.exp(-beta*cv2.merge((ldepth, ldepth, ldepth)))\n",
    "            \n",
    "            rt = np.exp(-beta*cv2.merge((rdepth, rdepth, rdepth)))\n",
    "            \n",
    "            lI = 255*(np.multiply(limg,lt)+alpha*(1-lt))\n",
    "            \n",
    "            rI = 255*(np.multiply(rimg,rt)+alpha*(1-rt))\n",
    "            \n",
    "            lI = lI.astype(np.uint8)\n",
    "            \n",
    "            rI = rI.astype(np.uint8)\n",
    "            \n",
    "            name = folder.split('\\\\')[-1]\n",
    "            \n",
    "            alphabeta_info = 'alpha:  ' + str(alpha) + '   beta:  ' + str(beta)      \n",
    "\n",
    "            img_name1 = name+'_'+str(c)+'_1.png'\n",
    "            \n",
    "            img_name5 = name+'_'+str(c)+'_5.png'\n",
    "            \n",
    "            img_name_alphabeta[img_name1] = alphabeta_info\n",
    "            \n",
    "            img_name_alphabeta[img_name5] = alphabeta_info\n",
    "            \n",
    "            cv2.imwrite(output_dir_path + '/' + img_name1, lI)\n",
    "            \n",
    "            cv2.imwrite(output_dir_path + '/' + img_name5, rI)\n",
    "\n",
    "    info_path = os.path.join(output_dir_path,'alphabeta_info.txt')\n",
    "    \n",
    "    with open(info_path, 'w') as f:\n",
    "        \n",
    "        for img_name in img_name_alphabeta:\n",
    "            \n",
    "            f.write('%s           :' % str(img_name))\n",
    "            \n",
    "            f.write(str(img_name_alphabeta[img_name])+ '\\n')\n",
    "    \n",
    "    print(\"That's all...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    msd_dir_path = r'.\\data\\middlebury_2006'\n",
    "    \n",
    "    output_dir_path = r'.\\data\\middlebury_2006_hazy'\n",
    "    \n",
    "    generator_num_per_img=1  # 控制生成图数量\n",
    "    \n",
    "    haze_generator(msd_dir_path, output_dir_path, generator_num_per_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
